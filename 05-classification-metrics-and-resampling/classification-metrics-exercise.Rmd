---
title: "Classification Metrics"
author: "Filza Mazahir"
date: "November 8, 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(readr)
library(dplyr)
library(psych)
```


The German Credit Data (data/german_credit); 

1. Read in the German Credit Data
2. Partition the model into Test and Training Sets using only `base::sample` 
3. Train a model for `Creditability` 
4. Knit the document and submit both the this file Rmd and html files.

Show All Work! 

```{r}
gc <- read_csv("data/german_credit.csv")

#Sample Indexes
indices = sample(1:nrow(gc), size=0.2*nrow(gc))
 
# Split data
test_indices = gc[indices,]
dim(test_indices)  
train_indices = gc[-indices,]
print(train_indices)
dim(train_indices) 

#Train model
creditability_model <- lm( Creditability ~ . , train_indices )
print(creditability_model)

```


Using the `predict` function and `test` data, write functions to calculate and 
calculate: 

* Misclassification Rate
* Prevalence 
* Accuracy
* Accuracy
* Error Rate / Misclassification Rate
* True Positive Rate  
* False Positive Rate
* True Negative Rate  
* False Negative Rate 
* Sensitivity 
* Specificity 
* Recall 
* Precision

```{r}
#misclassificationrate <- function(arg1, arg2, ... ){
#mean(y_predicted != y_actual)
#return(object)
#}
prediction <- predict(creditability_model, test_indices)
print(prediction)

misclassificationrate <- mean(prediction != test_indices$Creditability)
print(misclassificationrate)


```
